import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import StandardScaler

from sklearn.ensemble import RandomForestRegressor

from sklearn.metrics import mean_squared_error, r2_score

np.random.seed(42)

days = np.arange(1, 101)

price = 50 + 0.5 * days + np.random.normal(0, 2, size=100)  

df = pd.DataFrame({"day": days, "price": price})

print("First 5 rows of dataset:\n", df.head())

X = df[['day']]  

y = df['price']  

scaler = StandardScaler()

X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(

   X_scaled, y, test_size=0.2, random_state=42

)

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)

print("\n Random Forest Results:")

print("MSE:", mean_squared_error(y_test, y_pred_rf))

print("R2 Score:", r2_score(y_test, y_pred_rf))

plt.scatter(X_test, y_test, color='blue', label="Actual")

plt.scatter(X_test, y_pred_rf, color='red', label="RF Predicted")

plt.title("Random Forest Predictions vs Actual")

plt.xlabel("Day (scaled)")

plt.ylabel("Stock Price")

plt.legend()

plt.show()

y_test_array = np.array(y_test)

sorted_idx = np.argsort(X_test.flatten())

plt.figure(figsize=(8,5))

plt.plot(X_test.flatten()[sorted_idx], y_test_array[sorted_idx], label="Actual", color="black")

plt.plot(X_test.flatten()[sorted_idx], y_pred_rf[sorted_idx], label="RF Predicted", color="red")

plt.title("Stock Price Prediction (Random Forest)")

plt.xlabel("Day (scaled)")

plt.ylabel("Price")

plt.legend()

plt.show()


import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import tensorflow as tf

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import Dense, Dropout

np.random.seed(42)

days = np.arange(1, 101)

price = 50 + 0.5 * days + np.random.normal(0, 2, size=100)  

df = pd.DataFrame({"day": days, "price": price})

print("First 5 rows of dataset:\n", df.head())

X = df[['day']]  

y = df['price']  

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_scaled = scaler.fit_transform(X)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(

   X_scaled, y, test_size=0.2, random_state=42

)

dl_model = Sequential([

   Dense(64, activation='relu', input_shape=(X_train.shape[1],)),

   Dropout(0.2),

   Dense(32, activation='relu'),

   Dense(1)  # Regression output (no activation)

])

dl_model.compile(optimizer='adam', loss='mse', metrics=['mae'])

history = dl_model.fit(X_train, y_train, validation_data=(X_test, y_test),

                      epochs=100, batch_size=8, verbose=0)

dl_mse, dl_mae = dl_model.evaluate(X_test, y_test, verbose=0)

print("\n Deep Learning Results:")

print("MSE:", dl_mse)

print("MAE:", dl_mae)

plt.plot(history.history['loss'], label='Train Loss')

plt.plot(history.history['val_loss'], label='Val Loss')

plt.title("DL Model Training Loss (MSE)")

plt.xlabel("Epochs")

plt.ylabel("Loss")

plt.legend()

plt.show()

y_pred_dl = dl_model.predict(X_test).flatten()

y_test_array = np.array(y_test)

sorted_idx = np.argsort(X_test.flatten())

plt.figure(figsize=(8,5))

plt.plot(X_test.flatten()[sorted_idx], y_test_array[sorted_idx], label="Actual", color="black")

plt.plot(X_test.flatten()[sorted_idx], y_pred_dl[sorted_idx], label="DL Predicted", color="green")

plt.title("Stock Price Prediction with Deep Learning")

plt.xlabel("Day (scaled)")

plt.ylabel("Price")

plt.legend()

plt.show()


import pandas as pd

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import LabelEncoder, StandardScaler

from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

import matplotlib.pyplot as plt

data = {

   'study_hours': [2, 5, 7, 1, 3, 8, 4, 6, 9, 2, 5, 7, 3, 8, 6],

   'attendance': [70, 90, 85, 60, 75, 95, 80, 88, 96, 65, 85, 92, 78, 94, 89],

   'parent_support': ['low', 'medium', 'high', 'low', 'medium',

                      'high', 'medium', 'high', 'high', 'low',

                      'medium', 'high', 'medium', 'high', 'medium'],

   'previous_score': [40, 65, 78, 30, 55, 85, 60, 70, 90, 35, 68, 80, 58, 87, 72],

   'pass_fail': ['fail', 'pass', 'pass', 'fail', 'fail',

                 'pass', 'fail', 'pass', 'pass', 'fail',

                 'pass', 'pass', 'fail', 'pass', 'pass']

}

df = pd.DataFrame(data)

le = LabelEncoder()

df['parent_support'] = le.fit_transform(df['parent_support'])

y = LabelEncoder().fit_transform(df['pass_fail'])

X = df.drop('pass_fail', axis=1)

X = StandardScaler().fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

rf_model.fit(X_train, y_train)

y_pred = rf_model.predict(X_test)

print("\nRandom Forest Results:")

print("Accuracy:", accuracy_score(y_test, y_pred))

print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

print("\nClassification Report:\n", classification_report(y_test, y_pred))

feat_importances = pd.Series(rf_model.feature_importances_, index=df.drop('pass_fail', axis=1).columns)

feat_importances.nlargest(4).plot(kind='barh', color="skyblue")

plt.title("Feature Importance - Random Forest")

plt.show()


import pandas as pd

import numpy as np

import matplotlib.pyplot as plt

import seaborn as sns

import tensorflow as tf

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import Dense, Dropout

data = {

   'study_hours': [2, 5, 7, 1, 3, 8, 4, 6, 9, 2, 5, 7, 3, 8, 6],

   'attendance': [70, 90, 85, 60, 75, 95, 80, 88, 96, 65, 85, 92, 78, 94, 89],

   'parent_support': ['low', 'medium', 'high', 'low', 'medium',

                      'high', 'medium', 'high', 'high', 'low',

                      'medium', 'high', 'medium', 'high', 'medium'],

   'previous_score': [40, 65, 78, 30, 55, 85, 60, 70, 90, 35, 68, 80, 58, 87, 72],

   'pass_fail': ['fail', 'pass', 'pass', 'fail', 'fail',

                 'pass', 'fail', 'pass', 'pass', 'fail',

                 'pass', 'pass', 'fail', 'pass', 'pass']

}

df = pd.DataFrame(data)

print("First 5 rows of dataset:\n", df.head())

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import LabelEncoder, StandardScaler

le = LabelEncoder()

df['parent_support'] = le.fit_transform(df['parent_support'])

X = df.drop('pass_fail', axis=1)

y = df['pass_fail']

y = LabelEncoder().fit_transform(y)

scaler = StandardScaler()

X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(

   X_scaled, y, test_size=0.2, random_state=42

)

dl_model = Sequential([

   Dense(32, activation='relu', input_shape=(X_train.shape[1],)),

   Dropout(0.2),

   Dense(16, activation='relu'),

   Dropout(0.2),

   Dense(1, activation='sigmoid')  # Binary classification

])

dl_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = dl_model.fit(X_train, y_train, validation_data=(X_test, y_test),

                      epochs=50, batch_size=4, verbose=0)

dl_loss, dl_acc = dl_model.evaluate(X_test, y_test, verbose=0)

print("\n Deep Learning Results:")

print("Accuracy:", dl_acc)

plt.plot(history.history['accuracy'], label='Train Accuracy')

plt.plot(history.history['val_accuracy'], label='Val Accuracy')

plt.title("DL Model Training History")

plt.xlabel("Epochs")

plt.ylabel("Accuracy")

plt.legend()

plt.show()
